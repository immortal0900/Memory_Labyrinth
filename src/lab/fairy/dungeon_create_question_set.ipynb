{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3281e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json \n",
    "from pathlib import Path\n",
    "\n",
    "def find_src_folder():\n",
    "    current = Path(os.getcwd()).resolve()\n",
    "    for p in [current] + list(current.parents):\n",
    "        src = p / \"src\"\n",
    "        if src.exists():\n",
    "            return src\n",
    "    raise RuntimeError(\"src 폴더를 찾을 수 없습니다.\")\n",
    "\n",
    "src_path = find_src_folder()\n",
    "sys.path.append(str(src_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.messages import SystemMessage, HumanMessage\n",
    "# from enums.LLM import LLM\n",
    "# import json\n",
    "\n",
    "# from lab.fairy.dungeon_create_dataset_prompts import (\n",
    "#     CREATE_QUESTION_DATASET_SYSTEM_PROMOT,\n",
    "#     CREATE_QUESTION_DATASET_USER_PROMOT,\n",
    "# )\n",
    "\n",
    "# maltus = [\n",
    "#     \"친근한 반말\",\n",
    "#     \"버릇없는 반말\",\n",
    "#     \"공손한 존댓말\",\n",
    "#     \"AI에게 명령하는 투\",\n",
    "#     \"귀엽고 장난스러운 말투\",\n",
    "#     \"차분한 해설조 말투\",\n",
    "#     \"흥분한 플레이어 말투\",\n",
    "#     \"지친/피곤한 말투\",\n",
    "#     \"은근 반말 섞인 존댓말\",\n",
    "#     \"무뚝뚝하고 단문 위주의 말투\",\n",
    "#     \"주어가 명확하지 않은 말투\",\n",
    "#     \"기계 같은 말투\",\n",
    "#     \"싸가지 없는 말투\",\n",
    "#     \"대충 말하는 말투\",\n",
    "#     \"열받은 말투\",\n",
    "#     \"짜증 섞인 말투\",\n",
    "#     \"비꼬는 말투\",\n",
    "#     \"냉소적인 말투\",\n",
    "#     \"맞춤법이 잘 안맞는 말투\",\n",
    "#     \"맞춤법이 잘 안맞고 어눌한 말투\",\n",
    "#     \"발음이 세는 말투\",\n",
    "# ]\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-5.2-2025-12-11\", temperature=1.0)\n",
    "# all_questions = []\n",
    "# for maltu in maltus:\n",
    "#     system_prompt = CREATE_QUESTION_DATASET_SYSTEM_PROMOT.format(maltoo=maltu)\n",
    "#     res = llm.invoke(\n",
    "#         [\n",
    "#             SystemMessage(content=system_prompt),\n",
    "#             HumanMessage(content=CREATE_QUESTION_DATASET_USER_PROMOT),\n",
    "#         ]\n",
    "#     )\n",
    "#     raw = res.content\n",
    "#     rows = json.loads(raw)\n",
    "#     all_questions.extend(rows)\n",
    "    \n",
    "# with open(\"fairy_dungeon_intent_questions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(all_questions, f, ensure_ascii=False, indent=2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b4232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "from enums.LLM import LLM\n",
    "import json\n",
    "from lab.fairy.dungeon_create_dataset_prompts import (\n",
    "    MONSTER_GUIDE_LABEL_SYSTEM_PROMPT,\n",
    "    EVENT_GUIDE_LABEL_SYSTEM_PROMPT,\n",
    "    DUNGEON_NAVIGATOR_LABEL_SYSTEM_PROMPT,\n",
    "    INTERACTION_HANDLER_LABEL_SYSTEM_PROMPT,\n",
    "    USAGE_GUIDE_LABEL_SYSTEM_PROMPT,\n",
    "    SMALLTALK_LABEL_SYSTEM_PROMPT,\n",
    "    UNKNOWN_INTENT_LABEL_SYSTEM_PROMPT,\n",
    "    HUMAN_PROMPT,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=LLM.GPT4_1_MINI, temperature=0.0)\n",
    "\n",
    "with open(\"fairy_dungeon_intent_questions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "QUESTIONS_JSON = json.dumps(questions, ensure_ascii=False)\n",
    "PROMPTS = {\n",
    "    \"MONSTER_GUIDE\": MONSTER_GUIDE_LABEL_SYSTEM_PROMPT,\n",
    "    \"EVENT_GUIDE\": EVENT_GUIDE_LABEL_SYSTEM_PROMPT,\n",
    "    \"DUNGEON_NAVIGATOR\": DUNGEON_NAVIGATOR_LABEL_SYSTEM_PROMPT,\n",
    "    \"INTERACTION_HANDLER\": INTERACTION_HANDLER_LABEL_SYSTEM_PROMPT,\n",
    "    \"USAGE_GUIDE\": USAGE_GUIDE_LABEL_SYSTEM_PROMPT,\n",
    "    \"SMALLTALK\": SMALLTALK_LABEL_SYSTEM_PROMPT,\n",
    "    \"UNKNOWN_INTENT\": UNKNOWN_INTENT_LABEL_SYSTEM_PROMPT,\n",
    "}\n",
    "\n",
    "def label_one(sys_prompt: str, text: str):\n",
    "    user_prompt = HUMAN_PROMPT.format(TEXT=text)\n",
    "    res = llm.invoke([\n",
    "        SystemMessage(content=sys_prompt),\n",
    "        HumanMessage(content=user_prompt),\n",
    "    ])\n",
    "    return json.loads(res.content)  \n",
    "\n",
    "for name, sys_prompt in PROMPTS.items():\n",
    "    out = []\n",
    "    for q in questions:\n",
    "        out.append(label_one(sys_prompt, q[\"text\"]))\n",
    "\n",
    "    with open(f\"labels_{name}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(out, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88763ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: fairy_dungeon_intent_dataset_merged.json count: 4863\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from lab.fairy.create_data_set import CreateDataSet, CreateDataSetGroup\n",
    "\n",
    "LABEL_FILES = [\n",
    "    (\"MONSTER_GUIDE\", \"labels_MONSTER_GUIDE.json\"),\n",
    "    (\"EVENT_GUIDE\", \"labels_EVENT_GUIDE.json\"),\n",
    "    (\"DUNGEON_NAVIGATOR\", \"labels_DUNGEON_NAVIGATOR.json\"),\n",
    "    (\"INTERACTION_HANDLER\", \"labels_INTERACTION_HANDLER.json\"),\n",
    "    (\"USAGE_GUIDE\", \"labels_USAGE_GUIDE.json\"),\n",
    "    (\"SMALLTALK\", \"labels_SMALLTALK.json\"),\n",
    "    (\"UNKNOWN_INTENT\", \"labels_UNKNOWN_INTENT.json\"),\n",
    "]\n",
    "\n",
    "\n",
    "def load_json(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize_rows(rows):\n",
    "    stack = [rows]\n",
    "    out = []\n",
    "\n",
    "    while stack:\n",
    "        cur = stack.pop()\n",
    "        if isinstance(cur, dict):\n",
    "            out.append(cur)\n",
    "        elif isinstance(cur, list):\n",
    "            stack.extend(cur)\n",
    "        else:\n",
    "            raise TypeError(f\"Unknown type: {type(cur)}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "merged: Dict[str, List[str]] = {}\n",
    "for label_name, path in LABEL_FILES:\n",
    "    rows = normalize_rows(load_json(path))\n",
    "\n",
    "    # === 여기 추가 ===\n",
    "    if isinstance(rows, dict) and \"samples\" in rows:\n",
    "        rows = rows[\"samples\"]\n",
    "\n",
    "    if isinstance(rows, list) and rows and isinstance(rows[0], list):\n",
    "        rows = [r for group in rows for r in group]\n",
    "    # =================\n",
    "\n",
    "    for r in rows:\n",
    "        text = r[\"text\"]\n",
    "        lab = r[\"label\"]\n",
    "\n",
    "        if text not in merged:\n",
    "            merged[text] = []\n",
    "        if lab != \"None\" and lab not in merged[text]:\n",
    "            merged[text].append(lab)\n",
    "\n",
    "# UNKNOWN_INTENT 처리\n",
    "for text, labs in merged.items():\n",
    "    if not labs:\n",
    "        labs.append(\"UNKNOWN_INTENT\")\n",
    "\n",
    "    if \"UNKNOWN_INTENT\" in labs and len(labs) > 1:\n",
    "        merged[text] = [\"UNKNOWN_INTENT\"]\n",
    "\n",
    "samples = [CreateDataSet(text=t, labels=merged[t]) for t in merged]\n",
    "group = CreateDataSetGroup(samples=samples)\n",
    "\n",
    "out_path = Path(\"fairy_dungeon_intent_dataset_merged.json\")\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(group.model_dump(), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"saved:\", out_path, \"count:\", len(group.samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e289c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjectML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
